{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d67037a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1faa262",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0421 02:13:13.266246 140632387766080 deprecation_wrapper.py:119] From /workdir/msc/cell-detector/keras-fcos/train.py:47: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f59e50",
   "metadata": {},
   "source": [
    "## Default IoU loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0a08d9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_type': 'pascal', 'snapshot': None, 'imagenet_weights': True, 'weights': None, 'backbone': 'resnet50', 'batch_size': 24, 'gpu': None, 'num_gpus': 0, 'multi_gpu_force': False, 'epochs': 50, 'steps': 10000, 'lr': 0.0001, 'snapshot_path': './snapshots/pascal_resnet50_iou', 'tensorboard_dir': 'logs/2021-04-21', 'snapshots': True, 'evaluation': True, 'freeze_backbone': True, 'random_transform': False, 'image_min_side': 256, 'image_max_side': 512, 'config': None, 'weighted_average': False, 'compute_val_loss': True, 'loss': 'iou', 'loss_weight': 1.0, 'multiprocessing': False, 'workers': 1, 'max_queue_size': 10, 'pascal_path': '/datasets/dataset/VOCdevkit/VOC2012'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0421 02:13:14.976303 140632387766080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0421 02:13:14.977439 140632387766080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0421 02:13:14.979440 140632387766080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0421 02:13:14.996368 140632387766080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1919: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0421 02:13:14.998683 140632387766080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0421 02:13:15.000476 140632387766080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model, this may take a second...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0421 02:13:16.045769 140632387766080 deprecation_wrapper.py:119] From /workdir/msc/cell-detector/keras-fcos/utils_graph.py:108: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "W0421 02:13:18.847994 140632387766080 deprecation.py:323] From /workdir/msc/cell-detector/keras-fcos/layers.py:273: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0421 02:13:19.612610 140632387766080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0421 02:13:24.365784 140632387766080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "W0421 02:13:24.366586 140632387766080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/msc/cell-detector/keras-fcos/generators/generator.py:258: UserWarning: Image with id 2948 (shape (375, 500, 3)) contains no valid boxes after transform\n",
      "  image.shape,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 38/586 [>.............................] - ETA: 6:17 - loss: 4.6146 - regression_loss: 3.1672 - classification_loss: 0.7717 - centerness_loss: 0.6757"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/msc/cell-detector/keras-fcos/generators/generator.py:258: UserWarning: Image with id 6717 (shape (333, 500, 3)) contains no valid boxes after transform\n",
      "  image.shape,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/586 [=====>........................] - ETA: 4:07 - loss: 3.1738 - regression_loss: 1.8896 - classification_loss: 0.6296 - centerness_loss: 0.6546"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/msc/cell-detector/keras-fcos/generators/generator.py:258: UserWarning: Image with id 348 (shape (375, 500, 3)) contains no valid boxes after transform\n",
      "  image.shape,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/586 [======>.......................] - ETA: 3:44 - loss: 3.0287 - regression_loss: 1.7613 - classification_loss: 0.6148 - centerness_loss: 0.6526"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/msc/cell-detector/keras-fcos/generators/generator.py:258: UserWarning: Image with id 12579 (shape (333, 500, 3)) contains no valid boxes after transform\n",
      "  image.shape,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/586 [=======>......................] - ETA: 3:33 - loss: 2.9689 - regression_loss: 1.7070 - classification_loss: 0.6101 - centerness_loss: 0.6519"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/msc/cell-detector/keras-fcos/generators/generator.py:258: UserWarning: Image with id 10685 (shape (375, 500, 3)) contains no valid boxes after transform\n",
      "  image.shape,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/586 [========>.....................] - ETA: 3:15 - loss: 2.8514 - regression_loss: 1.6059 - classification_loss: 0.5959 - centerness_loss: 0.6495"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/msc/cell-detector/keras-fcos/generators/generator.py:258: UserWarning: Image with id 5599 (shape (375, 500, 3)) contains no valid boxes after transform\n",
      "  image.shape,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264/586 [============>.................] - ETA: 2:31 - loss: 2.6572 - regression_loss: 1.4548 - classification_loss: 0.5581 - centerness_loss: 0.6442"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/msc/cell-detector/keras-fcos/generators/generator.py:258: UserWarning: Image with id 983 (shape (333, 500, 3)) contains no valid boxes after transform\n",
      "  image.shape,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/586 [=============>................] - ETA: 2:21 - loss: 2.6146 - regression_loss: 1.4218 - classification_loss: 0.5496 - centerness_loss: 0.6432"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/msc/cell-detector/keras-fcos/generators/generator.py:258: UserWarning: Image with id 7860 (shape (375, 500, 3)) contains no valid boxes after transform\n",
      "  image.shape,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456/586 [======================>.......] - ETA: 58s - loss: 2.3698 - regression_loss: 1.2436 - classification_loss: 0.4906 - centerness_loss: 0.6356"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/msc/cell-detector/keras-fcos/generators/generator.py:258: UserWarning: Image with id 4901 (shape (375, 500, 3)) contains no valid boxes after transform\n",
      "  image.shape,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458/586 [======================>.......] - ETA: 57s - loss: 2.3681 - regression_loss: 1.2425 - classification_loss: 0.4901 - centerness_loss: 0.6355"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/msc/cell-detector/keras-fcos/generators/generator.py:258: UserWarning: Image with id 1787 (shape (375, 500, 3)) contains no valid boxes after transform\n",
      "  image.shape,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503/586 [========================>.....] - ETA: 36s - loss: 2.3229 - regression_loss: 1.2084 - classification_loss: 0.4802 - centerness_loss: 0.6343"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/msc/cell-detector/keras-fcos/generators/generator.py:258: UserWarning: Image with id 5363 (shape (375, 500, 3)) contains no valid boxes after transform\n",
      "  image.shape,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/586 [============================>.] - ETA: 0s - loss: 2.2521 - regression_loss: 1.1574 - classification_loss: 0.4623 - centerness_loss: 0.6324"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/msc/cell-detector/keras-fcos/generators/generator.py:258: UserWarning: Image with id 192 (shape (375, 500, 3)) contains no valid boxes after transform\n",
      "  image.shape,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "586/586 [==============================] - 284s 485ms/step - loss: 2.2516 - regression_loss: 1.1570 - classification_loss: 0.4622 - centerness_loss: 0.6323 - val_loss: 2.0787 - val_regression_loss: 1.1139 - val_classification_loss: 0.3457 - val_centerness_loss: 0.6191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (2510 of 2510) |###| Elapsed Time: 0:01:35 Time:  0:01:35\n",
      "Parsing annotations: 100% (2510 of 2510) || Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 instances of class aeroplane with average precision: 0.5441\n",
      "177 instances of class bicycle with average precision: 0.5687\n",
      "243 instances of class bird with average precision: 0.4676\n",
      "150 instances of class boat with average precision: 0.1675\n",
      "252 instances of class bottle with average precision: 0.0994\n",
      "114 instances of class bus with average precision: 0.1615\n",
      "625 instances of class car with average precision: 0.4698\n",
      "190 instances of class cat with average precision: 0.7068\n",
      "398 instances of class chair with average precision: 0.1928\n",
      "123 instances of class cow with average precision: 0.2663\n",
      "112 instances of class diningtable with average precision: 0.1628\n",
      "257 instances of class dog with average precision: 0.5622\n",
      "180 instances of class horse with average precision: 0.4709\n",
      "172 instances of class motorbike with average precision: 0.4779\n",
      "2332 instances of class person with average precision: 0.5312\n",
      "266 instances of class pottedplant with average precision: 0.1450\n",
      "127 instances of class sheep with average precision: 0.2832\n",
      "124 instances of class sofa with average precision: 0.1601\n",
      "152 instances of class train with average precision: 0.5956\n",
      "158 instances of class tvmonitor with average precision: 0.3468\n",
      "mAP: 0.3690\n",
      "\n",
      "Epoch 00001: mAP improved from -inf to 0.36901, saving model to ./snapshots/pascal_resnet50_iou/resnet50_pascal.h5\n",
      "Epoch 2/50\n",
      "170/586 [=======>......................] - ETA: 2:24 - loss: 1.7577 - regression_loss: 0.8130 - classification_loss: 0.3285 - centerness_loss: 0.6163"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/msc/cell-detector/keras-fcos/generators/generator.py:258: UserWarning: Image with id 5363 (shape (375, 500, 3)) contains no valid boxes after transform\n",
      "  image.shape,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/586 [=======>......................] - ETA: 2:23 - loss: 1.7533 - regression_loss: 0.8095 - classification_loss: 0.3276 - centerness_loss: 0.6162"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/msc/cell-detector/keras-fcos/generators/generator.py:258: UserWarning: Image with id 4901 (shape (375, 500, 3)) contains no valid boxes after transform\n",
      "  image.shape,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217/586 [==========>...................] - ETA: 2:08 - loss: 1.7439 - regression_loss: 0.8020 - classification_loss: 0.3257 - centerness_loss: 0.6163"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/msc/cell-detector/keras-fcos/generators/generator.py:258: UserWarning: Image with id 2948 (shape (375, 500, 3)) contains no valid boxes after transform\n",
      "  image.shape,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305/586 [==============>...............] - ETA: 1:37 - loss: 1.7496 - regression_loss: 0.8126 - classification_loss: 0.3214 - centerness_loss: 0.6156"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/msc/cell-detector/keras-fcos/generators/generator.py:258: UserWarning: Image with id 7860 (shape (375, 500, 3)) contains no valid boxes after transform\n",
      "  image.shape,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/586 [===============>..............] - ETA: 1:31 - loss: 1.7498 - regression_loss: 0.8133 - classification_loss: 0.3210 - centerness_loss: 0.6155"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/msc/cell-detector/keras-fcos/generators/generator.py:258: UserWarning: Image with id 348 (shape (375, 500, 3)) contains no valid boxes after transform\n",
      "  image.shape,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331/586 [===============>..............] - ETA: 1:28 - loss: 1.7484 - regression_loss: 0.8119 - classification_loss: 0.3210 - centerness_loss: 0.6154"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/msc/cell-detector/keras-fcos/generators/generator.py:258: UserWarning: Image with id 5599 (shape (375, 500, 3)) contains no valid boxes after transform\n",
      "  image.shape,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431/586 [=====================>........] - ETA: 54s - loss: 1.7223 - regression_loss: 0.7905 - classification_loss: 0.3172 - centerness_loss: 0.6146"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/msc/cell-detector/keras-fcos/generators/generator.py:258: UserWarning: Image with id 12579 (shape (333, 500, 3)) contains no valid boxes after transform\n",
      "  image.shape,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445/586 [=====================>........] - ETA: 49s - loss: 1.7178 - regression_loss: 0.7874 - classification_loss: 0.3159 - centerness_loss: 0.6145"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/msc/cell-detector/keras-fcos/generators/generator.py:258: UserWarning: Image with id 10685 (shape (375, 500, 3)) contains no valid boxes after transform\n",
      "  image.shape,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/586 [=========================>....] - ETA: 26s - loss: 1.7109 - regression_loss: 0.7839 - classification_loss: 0.3129 - centerness_loss: 0.6140"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/msc/cell-detector/keras-fcos/generators/generator.py:258: UserWarning: Image with id 1787 (shape (375, 500, 3)) contains no valid boxes after transform\n",
      "  image.shape,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "542/586 [==========================>...] - ETA: 15s - loss: 1.7064 - regression_loss: 0.7809 - classification_loss: 0.3116 - centerness_loss: 0.6138"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/msc/cell-detector/keras-fcos/generators/generator.py:258: UserWarning: Image with id 6717 (shape (333, 500, 3)) contains no valid boxes after transform\n",
      "  image.shape,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/586 [============================>.] - ETA: 0s - loss: 1.7002 - regression_loss: 0.7762 - classification_loss: 0.3103 - centerness_loss: 0.6137"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/msc/cell-detector/keras-fcos/generators/generator.py:258: UserWarning: Image with id 192 (shape (375, 500, 3)) contains no valid boxes after transform\n",
      "  image.shape,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "586/586 [==============================] - 234s 400ms/step - loss: 1.7001 - regression_loss: 0.7761 - classification_loss: 0.3103 - centerness_loss: 0.6137 - val_loss: 1.6793 - val_regression_loss: 0.7799 - val_classification_loss: 0.2872 - val_centerness_loss: 0.6122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (2510 of 2510) |###| Elapsed Time: 0:01:00 Time:  0:01:00\n",
      "Parsing annotations: 100% (2510 of 2510) || Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 instances of class aeroplane with average precision: 0.6500\n",
      "177 instances of class bicycle with average precision: 0.5960\n",
      "243 instances of class bird with average precision: 0.5461\n",
      "150 instances of class boat with average precision: 0.3652\n",
      "252 instances of class bottle with average precision: 0.1802\n",
      "114 instances of class bus with average precision: 0.5063\n",
      "625 instances of class car with average precision: 0.5670\n",
      "190 instances of class cat with average precision: 0.7835\n",
      "398 instances of class chair with average precision: 0.2682\n",
      "123 instances of class cow with average precision: 0.4305\n",
      "112 instances of class diningtable with average precision: 0.3461\n",
      "257 instances of class dog with average precision: 0.6450\n",
      "180 instances of class horse with average precision: 0.4682\n",
      "172 instances of class motorbike with average precision: 0.6088\n",
      "2332 instances of class person with average precision: 0.5151\n",
      "266 instances of class pottedplant with average precision: 0.1681\n",
      "127 instances of class sheep with average precision: 0.4589\n",
      "124 instances of class sofa with average precision: 0.3993\n",
      "152 instances of class train with average precision: 0.6984\n",
      "158 instances of class tvmonitor with average precision: 0.5729\n",
      "mAP: 0.4887\n",
      "\n",
      "Epoch 00002: mAP improved from 0.36901 to 0.48870, saving model to ./snapshots/pascal_resnet50_iou/resnet50_pascal.h5\n",
      "Epoch 3/50\n",
      "503/586 [========================>.....] - ETA: 28s - loss: 1.5904 - regression_loss: 0.6968 - classification_loss: 0.2844 - centerness_loss: 0.6093"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/msc/cell-detector/keras-fcos/generators/generator.py:258: UserWarning: Image with id 983 (shape (333, 500, 3)) contains no valid boxes after transform\n",
      "  image.shape,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "586/586 [==============================] - 234s 399ms/step - loss: 1.5805 - regression_loss: 0.6884 - classification_loss: 0.2831 - centerness_loss: 0.6089 - val_loss: 1.5105 - val_regression_loss: 0.6175 - val_classification_loss: 0.2842 - val_centerness_loss: 0.6088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (2510 of 2510) |###| Elapsed Time: 0:00:59 Time:  0:00:59\n",
      "Parsing annotations: 100% (2510 of 2510) || Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 instances of class aeroplane with average precision: 0.6836\n",
      "177 instances of class bicycle with average precision: 0.6753\n",
      "243 instances of class bird with average precision: 0.5870\n",
      "150 instances of class boat with average precision: 0.4369\n",
      "252 instances of class bottle with average precision: 0.3456\n",
      "114 instances of class bus with average precision: 0.5737\n",
      "625 instances of class car with average precision: 0.6130\n",
      "190 instances of class cat with average precision: 0.8164\n",
      "398 instances of class chair with average precision: 0.3461\n",
      "123 instances of class cow with average precision: 0.5035\n",
      "112 instances of class diningtable with average precision: 0.4572\n",
      "257 instances of class dog with average precision: 0.7761\n",
      "180 instances of class horse with average precision: 0.5589\n",
      "172 instances of class motorbike with average precision: 0.6497\n",
      "2332 instances of class person with average precision: 0.6506\n",
      "266 instances of class pottedplant with average precision: 0.3279\n",
      "127 instances of class sheep with average precision: 0.4279\n",
      "124 instances of class sofa with average precision: 0.3864\n",
      "152 instances of class train with average precision: 0.7279\n",
      "158 instances of class tvmonitor with average precision: 0.6029\n",
      "mAP: 0.5573\n",
      "\n",
      "Epoch 00003: mAP improved from 0.48870 to 0.55734, saving model to ./snapshots/pascal_resnet50_iou/resnet50_pascal.h5\n",
      "Epoch 4/50\n",
      "586/586 [==============================] - 234s 399ms/step - loss: 1.5133 - regression_loss: 0.6421 - classification_loss: 0.2651 - centerness_loss: 0.6060 - val_loss: 1.5386 - val_regression_loss: 0.6638 - val_classification_loss: 0.2675 - val_centerness_loss: 0.6073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (2510 of 2510) |###| Elapsed Time: 0:01:00 Time:  0:01:00\n",
      "Parsing annotations: 100% (2510 of 2510) || Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 instances of class aeroplane with average precision: 0.7250\n",
      "177 instances of class bicycle with average precision: 0.6775\n",
      "243 instances of class bird with average precision: 0.6399\n",
      "150 instances of class boat with average precision: 0.4959\n",
      "252 instances of class bottle with average precision: 0.2229\n",
      "114 instances of class bus with average precision: 0.6429\n",
      "625 instances of class car with average precision: 0.6500\n",
      "190 instances of class cat with average precision: 0.8327\n",
      "398 instances of class chair with average precision: 0.4146\n",
      "123 instances of class cow with average precision: 0.5332\n",
      "112 instances of class diningtable with average precision: 0.4797\n",
      "257 instances of class dog with average precision: 0.7466\n",
      "180 instances of class horse with average precision: 0.6703\n",
      "172 instances of class motorbike with average precision: 0.6911\n",
      "2332 instances of class person with average precision: 0.6944\n",
      "266 instances of class pottedplant with average precision: 0.3463\n",
      "127 instances of class sheep with average precision: 0.4847\n",
      "124 instances of class sofa with average precision: 0.4715\n",
      "152 instances of class train with average precision: 0.7577\n",
      "158 instances of class tvmonitor with average precision: 0.6173\n",
      "mAP: 0.5897\n",
      "\n",
      "Epoch 00004: mAP improved from 0.55734 to 0.58972, saving model to ./snapshots/pascal_resnet50_iou/resnet50_pascal.h5\n",
      "Epoch 5/50\n",
      "586/586 [==============================] - 235s 400ms/step - loss: 1.4555 - regression_loss: 0.6042 - classification_loss: 0.2476 - centerness_loss: 0.6037 - val_loss: 1.4702 - val_regression_loss: 0.6143 - val_classification_loss: 0.2510 - val_centerness_loss: 0.6050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (2510 of 2510) |###| Elapsed Time: 0:00:59 Time:  0:00:59\n",
      "Parsing annotations: 100% (2510 of 2510) || Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 instances of class aeroplane with average precision: 0.7383\n",
      "177 instances of class bicycle with average precision: 0.6886\n",
      "243 instances of class bird with average precision: 0.6692\n",
      "150 instances of class boat with average precision: 0.5121\n",
      "252 instances of class bottle with average precision: 0.3269\n",
      "114 instances of class bus with average precision: 0.6267\n",
      "625 instances of class car with average precision: 0.6581\n",
      "190 instances of class cat with average precision: 0.8604\n",
      "398 instances of class chair with average precision: 0.4429\n",
      "123 instances of class cow with average precision: 0.6024\n",
      "112 instances of class diningtable with average precision: 0.5414\n",
      "257 instances of class dog with average precision: 0.7931\n",
      "180 instances of class horse with average precision: 0.6916\n",
      "172 instances of class motorbike with average precision: 0.6936\n",
      "2332 instances of class person with average precision: 0.6891\n",
      "266 instances of class pottedplant with average precision: 0.3594\n",
      "127 instances of class sheep with average precision: 0.5903\n",
      "124 instances of class sofa with average precision: 0.5222\n",
      "152 instances of class train with average precision: 0.7787\n",
      "158 instances of class tvmonitor with average precision: 0.6332\n",
      "mAP: 0.6209\n",
      "\n",
      "Epoch 00005: mAP improved from 0.58972 to 0.62092, saving model to ./snapshots/pascal_resnet50_iou/resnet50_pascal.h5\n",
      "Epoch 6/50\n",
      "586/586 [==============================] - 234s 399ms/step - loss: 1.4127 - regression_loss: 0.5757 - classification_loss: 0.2354 - centerness_loss: 0.6016 - val_loss: 1.4032 - val_regression_loss: 0.5541 - val_classification_loss: 0.2458 - val_centerness_loss: 0.6032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (2510 of 2510) |###| Elapsed Time: 0:00:59 Time:  0:00:59\n",
      "Parsing annotations: 100% (2510 of 2510) || Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 instances of class aeroplane with average precision: 0.7270\n",
      "177 instances of class bicycle with average precision: 0.6859\n",
      "243 instances of class bird with average precision: 0.6321\n",
      "150 instances of class boat with average precision: 0.5315\n",
      "252 instances of class bottle with average precision: 0.4089\n",
      "114 instances of class bus with average precision: 0.6016\n",
      "625 instances of class car with average precision: 0.6880\n",
      "190 instances of class cat with average precision: 0.8693\n",
      "398 instances of class chair with average precision: 0.4270\n",
      "123 instances of class cow with average precision: 0.6143\n",
      "112 instances of class diningtable with average precision: 0.5187\n",
      "257 instances of class dog with average precision: 0.7933\n",
      "180 instances of class horse with average precision: 0.7086\n",
      "172 instances of class motorbike with average precision: 0.7150\n",
      "2332 instances of class person with average precision: 0.7192\n",
      "266 instances of class pottedplant with average precision: 0.3662\n",
      "127 instances of class sheep with average precision: 0.6140\n",
      "124 instances of class sofa with average precision: 0.5901\n",
      "152 instances of class train with average precision: 0.7997\n",
      "158 instances of class tvmonitor with average precision: 0.6719\n",
      "mAP: 0.6341\n",
      "\n",
      "Epoch 00006: mAP improved from 0.62092 to 0.63413, saving model to ./snapshots/pascal_resnet50_iou/resnet50_pascal.h5\n",
      "Epoch 7/50\n",
      "586/586 [==============================] - 234s 399ms/step - loss: 1.3806 - regression_loss: 0.5531 - classification_loss: 0.2273 - centerness_loss: 0.6002 - val_loss: 1.4122 - val_regression_loss: 0.5725 - val_classification_loss: 0.2365 - val_centerness_loss: 0.6032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network:  33% (830 of 2510) |#   | Elapsed Time: 0:00:19 ETA:   0:00:39"
     ]
    }
   ],
   "source": [
    "args = '--backbone resnet50 \\\n",
    "--lr 1e-4 \\\n",
    "--snapshot-path ./snapshots/pascal_resnet50_iou \\\n",
    "--batch-size 24 \\\n",
    "--epochs 50 \\\n",
    "--compute-val-loss \\\n",
    "--image-min-side 256 \\\n",
    "--image-max-side 512 \\\n",
    "--freeze-backbone \\\n",
    "pascal /datasets/dataset/VOCdevkit/VOC2012'\n",
    "\n",
    "args = parse_args(args.split(' '))\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103eceb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = '--backbone resnet50 \\\n",
    "--snapshot ./snapshots/pascal_resnet50_iou/resnet50_pascal.h5 \\\n",
    "--lr 1e-4 \\\n",
    "--snapshot-path ./snapshots/pascal_resnet50_iou/finetuned \\\n",
    "--batch-size 24 \\\n",
    "--epochs 50 \\\n",
    "--compute-val-loss \\\n",
    "--image-min-side 256 \\\n",
    "--image-max-side 512 \\\n",
    "pascal /datasets/dataset/VOCdevkit/VOC2012'\n",
    "\n",
    "args = parse_args(args.split(' '))\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12c129f",
   "metadata": {},
   "source": [
    "## GIoU loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cb808a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = '--backbone resnet50 \\\n",
    "--lr 1e-4 \\\n",
    "--snapshot-path ./snapshots/pascal_resnet50_giou \\\n",
    "--batch-size 24 \\\n",
    "--epochs 50 \\\n",
    "--compute-val-loss \\\n",
    "--image-min-side 256 \\\n",
    "--image-max-side 512 \\\n",
    "--freeze-backbone \\\n",
    "--loss giou \\\n",
    "pascal /datasets/dataset/VOCdevkit/VOC2012'\n",
    "\n",
    "args = parse_args(args.split(' '))\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1968520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = '--backbone resnet50 \\\n",
    "--snapshot ./snapshots/pascal_resnet50_giou/resnet50_pascal.h5 \\\n",
    "--lr 1e-4 \\\n",
    "--snapshot-path ./snapshots/pascal_resnet50_giou/finetuned \\\n",
    "--batch-size 24 \\\n",
    "--epochs 50 \\\n",
    "--compute-val-loss \\\n",
    "--image-min-side 256 \\\n",
    "--image-max-side 512 \\\n",
    "--loss giou \\\n",
    "pascal /datasets/dataset/VOCdevkit/VOC2012'\n",
    "\n",
    "args = parse_args(args.split(' '))\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed5707a",
   "metadata": {},
   "source": [
    "## ProbIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ce193c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = '--backbone resnet50 \\\n",
    "--lr 1e-4 \\\n",
    "--snapshot-path ./snapshots/pascal_resnet50_probiou \\\n",
    "--batch-size 24 \\\n",
    "--epochs 50 \\\n",
    "--compute-val-loss \\\n",
    "--image-min-side 256 \\\n",
    "--image-max-side 512 \\\n",
    "--freeze-backbone \\\n",
    "--loss piou_l3 \\\n",
    "--loss_weight 10 \\\n",
    "pascal /datasets/dataset/VOCdevkit/VOC2012'\n",
    "\n",
    "args = parse_args(args.split(' '))\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894aed77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = '--backbone resnet50 \\\n",
    "--snapshot ./snapshots/pascal_resnet50_probiou/resnet50_pascal.h5 \\\n",
    "--lr 1e-4 \\\n",
    "--snapshot-path ./snapshots/pascal_resnet50_probiou/finetuned \\\n",
    "--batch-size 24 \\\n",
    "--epochs 50 \\\n",
    "--compute-val-loss \\\n",
    "--image-min-side 256 \\\n",
    "--image-max-side 512 \\\n",
    "--loss piou_l1 \\\n",
    "--loss_weight 2 \\\n",
    "pascal /datasets/dataset/VOCdevkit/VOC2012'\n",
    "\n",
    "args = parse_args(args.split(' '))\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ef55cd",
   "metadata": {},
   "source": [
    "## CIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d613a0e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = '--backbone resnet50 \\\n",
    "--lr 1e-4 \\\n",
    "--snapshot-path ./snapshots/pascal_resnet50_ciou \\\n",
    "--batch-size 24 \\\n",
    "--epochs 50 \\\n",
    "--compute-val-loss \\\n",
    "--image-min-side 256 \\\n",
    "--image-max-side 512 \\\n",
    "--freeze-backbone \\\n",
    "--loss ciou \\\n",
    "pascal /datasets/dataset/VOCdevkit/VOC2012'\n",
    "\n",
    "args = parse_args(args.split(' '))\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec8033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = '--backbone resnet50 \\\n",
    "--snapshot ./snapshots/pascal_resnet50_ciou/resnet50_pascal.h5 \\\n",
    "--lr 1e-4 \\\n",
    "--snapshot-path ./snapshots/pascal_resnet50_ciou/finetuned \\\n",
    "--batch-size 24 \\\n",
    "--epochs 50 \\\n",
    "--compute-val-loss \\\n",
    "--image-min-side 256 \\\n",
    "--image-max-side 512 \\\n",
    "--loss ciou \\\n",
    "pascal /datasets/dataset/VOCdevkit/VOC2012'\n",
    "\n",
    "args = parse_args(args.split(' '))\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7ed26f",
   "metadata": {},
   "source": [
    "## DIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e291bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = '--backbone resnet50 \\\n",
    "--lr 1e-4 \\\n",
    "--snapshot-path ./snapshots/pascal_resnet50_diou \\\n",
    "--batch-size 24 \\\n",
    "--epochs 50 \\\n",
    "--compute-val-loss \\\n",
    "--image-min-side 256 \\\n",
    "--image-max-side 512 \\\n",
    "--freeze-backbone \\\n",
    "--loss diou \\\n",
    "pascal /datasets/dataset/VOCdevkit/VOC2012'\n",
    "\n",
    "args = parse_args(args.split(' '))\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae74f334",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = '--backbone resnet50 \\\n",
    "--snapshot ./snapshots/pascal_resnet50_diou/resnet50_pascal.h5 \\\n",
    "--lr 1e-4 \\\n",
    "--snapshot-path ./snapshots/pascal_resnet50_diou/finetuned \\\n",
    "--batch-size 24 \\\n",
    "--epochs 50 \\\n",
    "--compute-val-loss \\\n",
    "--image-min-side 256 \\\n",
    "--image-max-side 512 \\\n",
    "--loss diou \\\n",
    "pascal /datasets/dataset/VOCdevkit/VOC2012'\n",
    "\n",
    "args = parse_args(args.split(' '))\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffd2fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
